> <h2>2020/11/21</h2>

- AWS SageMaker 쓰기로 결정

  SageMaker는 쉽고 빠르게 구성, 학습하고 기계 학습 모델을 배포할 수 있도록 해주는 관리형 서비스!

  Serverless로 구성하기 위해서는 SageMaker에서 EndPoint를 만들어준 다음 이 EndPoint를 람다와 연결해주어야 함

- 궁금한 점   

  S3에 있는 마스크 이미지들을 SageMaker의 Notebook Instance에서 가져와서 사용하는 방법?

  S3로 SageMaker 엔드포인트를 만들 수 있나? -> S3에 모델을 저장하고, 엔드포인트는 엔드포인트 따로 만드는 듯   
  
  

> <h2>2020/11/23</h2>

- AWS RDS 쓰기로 결정

  DynamoDB 쓸까도 했지만 db를 이용하는 경우는 관리자 앱, 웹 뿐이므로 속도가 크게 문제될 것 같지 않음

- 테이블 구조

  ```
  mysql> CREATE TABLE history (
      -> `id` int(11) NOT NULL AUTO_INCREMENT,
      -> `ispass` TINYINT(1) NOT NULL,
      -> `visited` DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
      -> PRIMARY KEY(id)
      -> );
  Query OK, 0 rows affected, 2 warnings (0.21 sec)
  mysql> set time_zone='Asia/Seoul';
  ```

  통과되었는지 안 되었는지(ispass), 방문한 시간(visited)

  -> 통과 안되다가 통과한 것을 어떻게 처리할 것인지 생각해보기 -> 그냥 누적되도록 결정!

  

> <h2>2020/11/24</h2>

- AWS IoT Greengrass를 쓰자

  HTTP 통신도 가능하지만 빠른 데이터 처리를 위해 더 좋은 방법

  AI 모델을 로컬 디바이스 내에서 바로 사용 가능 (클라우드와 연결이 끊어져도 사용 가능)

  - 구현 순서

    1. 라즈베리파이에 Greengrass 그룹 배포 (설치 및 환경 구축)

    2. 이미지 분류 모델 구축(SageMaker)
    3. 사진 찍어서 모델로 예측하는 람다 함수 생성 후 Greengrass 그룹의 람다로 추가
    4. Greengrass 그룹에 머신러닝 리소스 생성 (모델 선택해서)
    5. AWS IoT Greengrass Image Classification 커넥터 생성 (람다 함수가 모델에 접근 가능해짐)
    6. 캡쳐할 이미지를 저장할 로컬 디렉터리 구성(AWS, 라즈베리파이 둘 다)
    7. [테스트]를 사용해서 구독 구성. 이벤트 트리거는 여러 가지가 있음. response topic을 subscribe하고, request topic을 publish

- 궁금한 점

  SageMaker로 만든 모델을 쓰려면 같은 계정이어야 한다. S3에 올려서 사용하면 다른 계정이어도 가능하긴 할 것 같은데 맞나?

  사람이 카메라 앞으로 왔을 때 몇 초 간격으로 request할 수 있는지 물어보고 찾아보기



> <h2>2020/11/25</h2>

- Python boto3 라이브러리로 S3에 접근할 수 있도록 IAM 사용자 권한 설정

  AmazonS3FullAccess 권한

- 기획안 발표 PPT 작성  




> <h2>2020/11/26</h2>

- 기획안 발표날

- 클라우드반 AWS 계정을 받기 전 사용할 스펙?에 대해 조사하다가 클라우드 S3에 모델을 올리지 말라는 말을 들었다. 뭐 어떡하라는 거죠?"??????? 

- 테스트용으로 API Gateway로 GET 요청 보내는 리액트 웹 만들어서  

  Lambda 함수 호출로 경보 만들고 Cloudwatch 테스트해봄

![이미지 7](https://user-images.githubusercontent.com/30336831/100345055-19d14380-3025-11eb-9f75-4b1d1388a098.png)

이렇게 나온다

> <h2>2020/11/30</h2>

- 라즈베리파이 python에서 boto3 사용, s3로 이미지 바로 업로드하자

- 불필요한 이미지도 함께 저장될 것이므로, 처음에는 파일명을 'temp-어쩌구저쩌구'로 저장하고 확실한 리턴값이 나올 수 있는 이미지만 파일명 수정, 접미사 temp-인 파일들은 자동으로 한시간 안에 삭제되도록 구현할 예정

- 람다 함수 하나에 때려넣지 않고 분산 애플리케이션을 위해 Step Functions 사용하기로 결정

- S3 이미지 업로드 - CloudTrail - CloudWatch - Step Functions 구성으로 호출될 것임

  동작 방식 확인을 위해 개인 계정으로 테스트해봤고 성공! 

- Git Organization으로 바꿈


> <h2>2020/12/02</h2>

- RDS 데이터베이스 구축 완료

- 마스크 모델 예측 람다 임시로 구현, db에 통계 기록 저장하는 람다 구현 후 Step Functions 구성 완료

- IoT Core로 온도 데이터 전송하기로 결정!

  IoT Core 사물 구성, 규칙 생성, 메시지 게시할 시 Step Functions 호출되도록 구성해놓음

  `SELECT * FROM 'kf99/topic' where temperature > 30`

  에러메시지는 `kf99/error`

> <h2>2020/12/03</h2>

- 람다에서 모델 예측을 돌리는 게 비용 부담이 많이 된다고 한다.

  멘토님한테 한 번 물어보자............. 어쨌든 다시 변경

- EC2에 Django 서버 구축 완료

  라즈베리파이에서 Django 서버로 온도 데이터 전송(HTTP REST API)

  EC2에서 모델 예측 돌리고 Response 리턴

> <h2>2020/12/04</h2>

- Django Rest Framework로 REST API 구축 완료

  이미지 파일 받아서 저장하는 것까지!

  ```
  # 클라이언트 코드
  url = "http://3.35.94.100/mask/"
  image_file_descriptor = open('test.png', 'rb')
  files = {'file': image_file_descriptor}
  requests.post(url, files=files)
  image_file_descriptor.close()
  print(r.status_code, r.text)
  ```

- EC2 터미널을 꺼도 계속 Django가 돌아갈 수 있도록 uWSGI 서버와 Nginx 서버 연결해서 데몬으로 돌려놓음.

  이제 포트번호 없이 들어갈 수 있고, 인스턴스만 켜져 있으면 접속해볼 수 있다
  

> <h2>2020/12/05</h2>

- Tensorflow, Keras 등 ai 라이브러리를 사용하기 위해서는 EC2 t2.micro가 아닌 더 큰 EC2가 필요해서 ai반의 EC2를 이용하기로 했음
- 버전 때문에 uWSGI 서버가 설치가 안 되는 문제 발생. 찾아보니 uWSGI보다 더 가볍고 좋은 Gunicorn이라는 것이 있다고 해서 사용하기로 함
- Ai EC2에 Gunicorn 서버와 Nginx 서버 연결해서 Django 서버 구축 완료            



  

  