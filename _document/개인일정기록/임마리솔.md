## 201123

- with_mask / without_mask 데이터 수집
- 이미지 데이터 전처리 방법 학습(https://ivo-lee.tistory.com/91)
- 관련 자료 검색
  - https://www.kaggle.com/ayushimishra2809/face-mask-detection?select=Medical+mask



## 201124

- with_mask / without_mask(마스크 아예 없는 얼굴) 이미지 데이터 정상적인 것만 1000장씩 필터링하여 전송
- https://crystalcube.co.kr/192



## 201125

- AWS 환경 설정 + 필요한 패키지 설치
- 이미지 크로핑 연습해봄



## 201126

- 코스크, 턱스크 등 불량 마스크 이미지 수집중..
- 기획안 발표 참관



## 201127

- AWS에서 인스타 크롤링 위한 selenium, chrome 설치 ->완수하지 못함..ㅜ
- grayscale 이미지를 3채널 이미지로 변환하는 작업



## 201128

- 멘토링
  - 전체 멘토링
    - 코스크, 턱스크 이미지로 클러스터링 기법 적용
    - haar casscades (오브젝트 검출 알고리즘)
    - 데이터를 정규화(normalization)해야 함 -> 전처리 과정 필수
  - 빅데이터 멘토링
    - 이미지 전처리 부분은 ai 반에 맡기거나 배워서 하는 방향으로.. 우리는 크롤링 방법 사용...(우리의 역할을 확실히 할 수 있는 방향을 생각해봐라)
    - 빅데이터와 ai의 역할을 구분하지 마라. 함께 하는것.
    - 추가적으로 파생해서 새로운 모델링을 만드는 방법을 생각해봐라, 어떤 서비스를 추가로 더 집어넣을 수 있을지..



## 201130

- with_mask / without_mask(no_mask/chin_mask/nose_mask) class 나눠서 10,000개 이미지 배치 코딩
- 인물 이미지에 마스크 합성 연습(ing...)
  - [kaggle - Facemask Detection Dataset 20,000 Images](https://www.kaggle.com/pranavsingaraju/facemask-detection-dataset-20000-images)
  - [github - 마스크 합성하기](https://github.com/aqeelanwar/MaskTheFace)

- 김정현 강사님께 AWS 크롤링 환경설정 자료(selenium, chrome driver 설치) 전달 받음



## 201201

- 칼라 얼굴 이미지 10,000장 + 마스크 6종류 합성하여 데이터셋 구축(마스크 제대로 쓴 합성 이미지 완성)
  - [kaggle - Face Mask Lite Dataset (color)](https://www.kaggle.com/prasoonkottarathil/face-mask-lite-dataset)

- 코스크 합성 이미지 데이터셋 만들 예정..



## 201202

- 칼라 얼굴 이미지 10,000장 + 마스크 6종류 합성하여 데이터셋 구축(마스크 불량착용 합성 이미지 완성)
- 중간발표 (강사님께서 턱스크 데이터셋은 따로 안하냐고 물어보심.. 일단 코스크만 고려)
- AWS에서 selenium 사용 환경 설정(크롬 드라이버 설치) 성공
- 인스타 크롤링 해보는중..



## 201203

- 인스타 이미지 크롤링

  - 로컬에서 해봄 (aws에서 크롤링 할 때는 웹 브라우저 띄우지 못함..)
  - 스크롤 내리면서 끝까지 가져오는건 아직 못함

- 3 class(with/no/nose_mask)로 나눈 컬러 합성이미지로 학습된 모델이 판단은 잘됨 

  하지만 측면 코스크 이미지 잘 안되는 것들이 있음 -> 측면 고려하여 합성 다시 하기로 함



## 201204

- 측면 고려한 마스크, 코스크  합성 데이터셋 구축

  - 정면 이미지는 그대로 6종류 마스크 합성

  - 측면 이미지는 각도 고려하여 surgical(일반적인 비말) 마스크로만 left/right 구분하여 합성

    (KF94 마스크의 left/right 이미지가 따로 없음)

  - 측면 이미지만 따로 뽑아서 cloth(검정) 마스크로 left/right 구분하여 합성



## 201205

- 멘토링
  - 진전이 많이 된 것 같다..
- 인스타 이미지 크롤링(로컬)
  - #턱스크 검색해서 나오는 이미지 스크롤 내리며 총 1491개 가져옴
  - 그 중 마스크 판단 테스트용으로 쓰일 만한 것 251개 저장



## 201207

- 마스크 미착용자 신고 건수 데이터 수집(AWS에서 크롤링)
  - [안전신문고-마스크 미착용 신고](https://www.safetyreport.go.kr/#introduction/safeSingoStatistics)
  - 2020-09-01 ~ 현재까지의 일별 신고 건수

- 데이터 프레임으로 저장하고 간단한 시각화로 추이 확인
- 빅데이터(김정현) 강사님과 면담 및 9조 빅데이터 파트 중간보고
  - 현재까지의 코로나 확진자 현황을 가지고 간단한 시계열 분석을 통해 미래를 예측(아무런 변수가 없을 경우)
  - 프로젝트 주제 관련 코로나 현 상황에 대해 여러가지 통계 분석하여 프로젝트의 재미, 흥미를 높여라
  - 지도로 시각화 해봐라. 애니메이션? (지역별 확진자 수 통계 띄어주는데 월별(or 3개월씩 묶어서)로 애니메이션 적용
  - Q)관련 데이터 자료를 찾은게 있는데 pdf , hwp파일이다.. 
    - -> A)pdf 파일을 수정 작업? 또는 파이썬으로 pdf 파일을 텍스트 파일로 변환해서 가지고 오는 방법 있을수도...?



## 201208

- 마스크 미착용 신고 건수 데이터 선 그래프로 시각화
  - 11월부터 신고 건수가 크게 증가한 것으로 보임 
    - -> 아직도 마스크 미착용 신고가 많기 때문에 마스크 미착용자를 통제하는 우리 서비스가 꼭 필요하다!
- 파이썬으로 hwp파일 내용 읽어오기 연습
  - olefile 설치하면 됨
  - 그런데 주요 발생 원인별 현황 부분이 필요한데 딱 그부분만 못 가져옴...why..?



## 201209

- 중간 발표
- 파이썬으로 hwp 파일 내용 읽어오기
  - olefile 이용하여 읽어 오긴 했으나 전체 내용을 다 읽어오지는 못함... 이유 모르겠음ㅜ
  - 그래서 그냥 사이트에서 다운 받은 hwp 파일들을 txt 파일로 변환한 후, 파이썬으로 txt 파일을 읽어오는 방법으로 하기로 함
- pdf 파일 읽어오기도 PyPDF2, pdftotext, pdftotree, pdfminer, tika...  다 해봤으나 잘 안됨



## 201210

- hwp 파일은 일별 데이터가 아니라 누적 데이터 테이블이여서 일별 데이터 테이블이 있는 pdf 파일을 txt나 excel 파일로 변환 후

   활용하려 했으나 변환했을때 깨지는 파일들이 많아서 포기...

- 웹 사이트에서 크롤링 해올 수 있는 방법을 찾아서 그렇게 해보기로 함



## 201211

- (발생장소별) 서울 확진자 현황 일별(10.01~현재)로 크롤링하여 수집 후 데이터 전처리중...



## 201212

- 멘토링
- 서울시 장소별 확진자 현황 데이터 전처리 후 시각화 -> 학원, 회사, 병원에서 가장 많이 발생



## 201215

- 게이트 만들기 참여
- 일별 마스크 신고건수 데이터프레임을 mysql에 넣는 작업 -> 클라우드에서 관리자앱에 그래프로 띄어줄거임
  - 200901~201213까지의 데이터를 먼저 저장하고 그 이후의 데이터는 그날그날 업데이트 되도록..



## 201216

- 중간발표
- MySQL에 넣었던 데이터 불러와서 업데이트된걸로 그래프 다시 그려봄(이제 쥬피터랩 켤때마다 첨부터 크롤링 안해도 된당)
- 코로나 관련 데이터 분석, 시각화 마무으리!



## 201217~201223

- 게이트+감시카메라 제작
- 피피티 제작
- 시연영상 촬영
- 201219 : 최종 전 리허설 발표(멘토 피드백)
- 발표 준비